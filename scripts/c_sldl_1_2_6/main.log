2024-04-23 15:04:44.188518: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-23 15:04:44.906673: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-23 15:04:50.751969: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  8.0
step (sec):  6.0
overlap:  True
perc. of overlap:  25.0
Nearest multiple of 16 to 8000 is: 8000
Nearest multiple of 16 to 6000 is: 6000
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_6\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.

predicted [0.66188526 0.65773475 0.80364466 0.7351924  0.7155982  0.696205
 0.7507367  0.7892333  0.76514834 0.7371827  0.7001615  0.7852998
 0.7488965  0.8790998  0.77630055 0.68205047 0.7838538  0.701972
 0.77277696 0.7409675  0.6475194  0.72718644 0.8210043  0.72978604
 0.78101873 0.7247703  0.80199075 0.78757423 0.6733651  0.7757815
 0.6963799  0.7622713  0.7206572  0.7273891  0.7094946  0.62584627
 0.8734598  0.7233445  0.8693569  0.7666034  0.7052344 ]
predicted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]
expected [False  True False  True  True  True  True  True  True  True  True  True
  True  True  True  True False False  True  True  True False  True  True
 False  True  True  True False  True  True  True  True  True False  True
  True False  True  True False]
accuracy: 0.7560975609756098
confusion matrix: 
[[ 0 10]
 [ 0 31]]
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

       False       0.00      0.00      0.00        10
        True       0.76      1.00      0.86        31

    accuracy                           0.76        41
   macro avg       0.38      0.50      0.43        41
weighted avg       0.57      0.76      0.65        41

C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
macro avg f1-score: 0.4305555555555556
macro avg (UAR): 0.5
Sensitivity:  0.0
Specificity:  1.0
g-mean:  0.0
-------- Model Performance ----------: 
accuracy:  [0.75609756 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
gmean:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
f1_score:  [0.43055556 0.         0.         0.         0.         0.
 0.         0.         0.         0.        ]
UAR:  [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0. ]
Cohen Kappa score:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
Split Repetition number:  1
StratifiedShuffleSplit(n_splits=1, random_state=None, test_size=0.2,
            train_size=None)
TRAIN: [155 118 197  99  50 189 151 167 110   9 147 132  60  83 190  61   1 181
 168  55 137 193 169 182 138 171 142 100  98  70  19  80  12 115  35 201
  37 173  76  90 145  41  11  16  95  84 103  75 119  87 157 191  63 102
  39  36 200  26 178 122  40  66  10 112  15 192  79 133 139 183  27 113
 114 135 185 158  54 104 194 165  62  13 134  52 187   0  20 117  49   2
   4 172 188 154 152 186 156  14  77  46 204  85 184 202  30 131 127  73
 105  53 164 111  47   5 160  21  93 143  51  92 153 120 179 198 101 121
  44 196  28  74  17  58 109  24  42 144  67 163  89 126  91  97 150   3
 141  81 129 162 203  43   6  88 174 106  71 140 166  69 125  23  32 175
  48 123] TEST: [ 86  25  57 180 124 176 108   8  56  18 116  59 149  65  96  78 195  29
  33  31  64  68  38  94 107   7 170  82 177  22 128  72 148 199 130  34
 161 136 146 159  45]
(DL) TRAIN number of instances:  164
(DL) TEST number of instances:  41
(DL) Total number of instances (TRAIN+TEST):  205
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\convolutional\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(
----- train_GSR_AE -------
Model: "sequential_2"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ 1stConvL (Conv1D)               │ (None, 8000, 5)        │           105 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ 1stPoolL (AveragePooling1D)     │ (None, 2000, 5)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ 2ndConvL (Conv1D)               │ (None, 2000, 6)        │           306 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ 2ndPoolL (AveragePooling1D)     │ (None, 500, 6)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ up_sampling1d_4 (UpSampling1D)  │ (None, 2000, 6)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_transpose_4              │ (None, 2000, 6)        │           366 │
│ (Conv1DTranspose)               │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ up_sampling1d_5 (UpSampling1D)  │ (None, 8000, 6)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_transpose_5              │ (None, 8000, 1)        │           121 │
│ (Conv1DTranspose)               │                        │               │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
s[0m 7ms/step - binary_accuracy: 0.8132 - loss: 0.5057

[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 110ms/step
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 94ms/step 
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 94ms/step
predicted [0.29258803 0.5450533  0.7522028  0.36630055 0.3133286  0.6025876
 0.79454416 0.43943536 0.7429689  0.7999822  0.8141851  0.40988025
 0.57624376 0.66286826 0.7192936  0.33573708 0.7965262  0.53963923
 0.48719904 0.8371276  0.6625612  0.56265354 0.79162395 0.6799477
 0.33883557 0.8260244  0.6614876  0.65217674 0.6690072  0.7736588
 0.605373   0.6117943  0.22286177 0.6192633  0.66627556 0.6304101
 0.69815814 0.83041644 0.7519463  0.5755409  0.73927176]
predicted [0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1
 1 1 1 1]
expected [False  True  True False False  True  True  True  True False False False
  True  True  True False  True  True False  True False False  True  True
 False False  True  True False  True  True False  True  True  True  True
 False  True False  True  True]
accuracy: 0.7317073170731707
confusion matrix: 
[[ 7  9]
 [ 2 23]]
              precision    recall  f1-score   support

       False       0.78      0.44      0.56        16
        True       0.72      0.92      0.81        25

    accuracy                           0.73        41
   macro avg       0.75      0.68      0.68        41
weighted avg       0.74      0.73      0.71        41

macro avg f1-score: 0.6835087719298245
macro avg (UAR): 0.67875
Sensitivity:  0.4375
Specificity:  0.92
g-mean:  0.6344288770224761
-------- Model Performance ----------: 
accuracy:  [0.68292683 0.70731707 0.68292683 0.68292683 0.6097561  0.65853659
 0.70731707 0.68292683 0.75609756 0.73170732]
gmean:  [0.67082039 0.64807407 0.63245553 0.63245553 0.53385391 0.56124861
 0.54772256 0.63245553 0.70356236 0.63442888]
f1_score:  [0.67037724 0.67460317 0.65322056 0.65322056 0.56613757 0.60576923
 0.62727273 0.65322056 0.72883598 0.68350877]
UAR:  [0.6725  0.67    0.65    0.65    0.5675  0.6075  0.63625 0.65    0.72125
 0.67875]
Cohen Kappa score:  [0.34116193 0.35602094 0.31047865 0.31047865 0.14136126 0.230563
 0.30704225 0.31047865 0.46335079 0.3880597 ]
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  8.0
step (sec):  6.0
overlap:  True
perc. of overlap:  25.0
Number of windows / instances:  205
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[ 0.688  0.848  0.849  0.842  0.842  0.513  0.755  0.785  0.743  0.755]
 [ 0.578  0.79   0.804  0.798  0.792  0.393  0.723  0.745  0.686  0.715]
 [ 0.611  0.828  0.839  0.826  0.83   0.507  0.742  0.78   0.761  0.746]
 [ 0.634  0.812  0.829  0.795  0.812  0.14   0.558  0.692  0.307  0.514]
 [ 0.588  0.797  0.815  0.79   0.802  0.402  0.682  0.771  0.567  0.677]
 [ 0.316  0.65   0.69   0.62   0.652 -0.03   0.488  0.629  0.12   0.416]
 [ 0.     0.5    0.61   0.     0.379  0.     0.5    0.663  0.     0.399]]
participant performance loaded
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
---------------------------
KNN performance:
[[0.45805647 0.72585859 0.73190476 0.71109206 0.72331743 0.44686908
  0.71395833 0.79452381 0.68134453 0.71738589]
 [0.51230151 0.75868687 0.75666667 0.75451452 0.75425333 0.44854043
  0.71973443 0.74238095 0.71235955 0.72345404]
 [0.50588862 0.7469697  0.765      0.7243779  0.74613699 0.4617033
  0.73131313 0.73190476 0.72000182 0.72642221]
 [0.31009596 0.6530303  0.66309524 0.64166444 0.65215799 0.25462094
  0.6202381  0.7002381  0.58368461 0.62348273]
 [0.56541497 0.77313034 0.80095238 0.75742143 0.77964315 0.46280507
  0.73136364 0.73142857 0.72480266 0.72844327]
 [0.41447025 0.70732323 0.70785714 0.70375462 0.70583466 0.59853077
  0.79909091 0.80095238 0.79624038 0.79853858]
 [0.27800783 0.63595085 0.6647619  0.60949946 0.63425229 0.35736045
  0.67909091 0.67785714 0.67217245 0.67527199]
 [0.89285714 0.93333333 0.95571429 0.93086085 0.94630599 0.54688668
  0.77772436 0.78071429 0.77224054 0.77125222]
 [0.37825224 0.68690476 0.74119048 0.65858068 0.68500103 0.22760674
  0.60452381 0.69309524 0.54945871 0.60934034]
 [0.32557783 0.66318182 0.66238095 0.65501127 0.65878633 0.34465222
  0.66977273 0.67857143 0.65849036 0.66875633]
 [0.12447169 0.56287393 0.58642857 0.53271677 0.55536696 0.47584206
  0.73215812 0.75690476 0.70906271 0.73233975]
 [0.68406109 0.83523352 0.85309524 0.82580333 0.84006959 0.50357933
  0.74855769 0.76190476 0.73952023 0.74855844]
 [0.36573899 0.67765152 0.70142857 0.65835738 0.67892094 0.10052427
  0.55031566 0.5652381  0.53466925 0.54895432]
 [0.08018488 0.53873626 0.59642857 0.48555145 0.53359002 0.34925132
  0.67429293 0.67880952 0.66332776 0.67064262]
 [0.32636327 0.65668498 0.71309524 0.62084619 0.65659758 0.3009588
  0.65315934 0.68404762 0.62563176 0.64329628]
 [0.43248964 0.7144765  0.73095238 0.7024131  0.7134504  0.43520843
  0.70457875 0.76119048 0.67752108 0.71365753]
 [0.5541746  0.78044872 0.78547619 0.77055814 0.77453663 0.32959313
  0.65897436 0.68857143 0.62521921 0.65507805]
 [0.16369264 0.56879085 0.8347619  0.29490122 0.5683497  0.29458391
  0.64706197 0.65904762 0.63968718 0.6450637 ]
 [0.38542962 0.68428571 0.74642857 0.65758774 0.68833766 0.4126067
  0.70674242 0.70833333 0.69841859 0.70260023]
 [0.27962771 0.63660714 0.68761905 0.5979564  0.6329864  0.25222849
  0.62129121 0.67404762 0.54920757 0.61588953]
 [0.07716953 0.53958333 0.72285714 0.31988329 0.5264393  0.1503397
  0.57545455 0.5752381  0.56778047 0.57152945]
 [0.28961572 0.64545455 0.64357143 0.61435929 0.62942367 0.32186699
  0.65357143 0.70714286 0.62492633 0.6576249 ]
 [0.11866291 0.55763889 0.57880952 0.51218594 0.54461713 0.32177559
  0.64541667 0.77071429 0.54510937 0.64724084]
 [0.26365305 0.63151515 0.63428571 0.62027172 0.62708477 0.43756692
  0.71636364 0.72738095 0.70487975 0.71601234]
 [0.40685804 0.69911616 0.71333333 0.68612515 0.70005898 0.61995053
  0.81045455 0.80928571 0.79615298 0.80408675]
 [0.39254311 0.69469697 0.70166667 0.68485329 0.69332123 0.48345037
  0.74065657 0.74714286 0.73273778 0.73959034]
 [0.43136866 0.70833333 0.77047619 0.68175072 0.71238253 0.49102563
  0.745      0.74619048 0.73879796 0.74312961]
 [0.28662316 0.64409341 0.67857143 0.61834047 0.6392877  0.46691662
  0.72825855 0.75142857 0.71047268 0.72930934]
 [0.25036032 0.62037546 0.66809524 0.57510868 0.61647457 0.34245116
  0.66974747 0.67833333 0.64833087 0.66373516]
 [0.68800439 0.84823718 0.84928571 0.84213314 0.84177094 0.51336359
  0.75457875 0.78547619 0.74313177 0.7549186 ]]
KNN mean:
[0.37473386 0.68430678 0.72153968 0.64828269 0.68195853 0.39175531
 0.6927815  0.71893651 0.6715127  0.69152018]
---------------------------
---------------------------
DT performance:
[[0.46658957 0.72545455 0.73095238 0.71467122 0.72183339 0.33742203
  0.698125   0.7852381  0.58127016 0.70453196]
 [0.39862254 0.70512626 0.70809524 0.67878984 0.70337705 0.39936588
  0.72156593 0.73690476 0.68767795 0.71870467]
 [0.41406615 0.69614899 0.70214286 0.69984317 0.69246121 0.37215662
  0.67565657 0.67785714 0.66603682 0.66867941]
 [0.25637442 0.62777778 0.63047619 0.6226709  0.62422043 0.23680782
  0.58833333 0.65309524 0.57258372 0.57984106]
 [0.35404435 0.68963675 0.70714286 0.66351894 0.68945958 0.40717177
  0.70318182 0.70261905 0.70338997 0.69967907]
 [0.50951206 0.70631313 0.70714286 0.7504015  0.70343837 0.54491411
  0.75166667 0.75595238 0.725012   0.74759105]
 [0.30909239 0.6650641  0.67428571 0.6204725  0.66176796 0.25907756
  0.64863636 0.64928571 0.62431036 0.64204947]
 [0.71761027 0.88690476 0.89238095 0.87824193 0.8782181  0.44937332
  0.75128205 0.75738095 0.72372789 0.74462699]
 [0.3176463  0.65928571 0.71666667 0.58083515 0.65738156 0.29928909
  0.66904762 0.71261905 0.62867255 0.66897244]
 [0.3256311  0.64818182 0.64809524 0.65660225 0.64106536 0.22651273
  0.5884596  0.5897619  0.62511273 0.58323839]
 [0.17448558 0.59348291 0.62452381 0.57119884 0.59120448 0.33245502
  0.68488248 0.69404762 0.68309152 0.68053395]
 [0.51127275 0.73427198 0.74595238 0.72922656 0.72769625 0.42361601
  0.68798077 0.69380952 0.6883651  0.68349819]
 [0.38897587 0.67001263 0.68214286 0.69874748 0.6697629  0.12359802
  0.57468434 0.58095238 0.54320656 0.56572065]
 [0.15365868 0.56119505 0.5747619  0.55749281 0.55247574 0.33816649
  0.64641414 0.64380952 0.63888138 0.64077196]
 [0.27866912 0.64130037 0.67833333 0.62741475 0.63712168 0.4132055
  0.68832418 0.70571429 0.6833652  0.67950467]
 [0.24279434 0.62094017 0.62857143 0.62533352 0.61680278 0.44771966
  0.71419414 0.74714286 0.71220133 0.70719025]
 [0.56951122 0.82767094 0.83404762 0.81303341 0.82629074 0.42434228
  0.72008547 0.72142857 0.70454349 0.71404632]
 [0.27783838 0.64199346 0.79547619 0.45346221 0.62453219 0.28451635
  0.6644765  0.67761905 0.66334377 0.66222337]
 [0.34341582 0.71380952 0.74547619 0.64520091 0.70062908 0.43090255
  0.71532828 0.71642857 0.68446991 0.71153687]
 [0.25812941 0.61236264 0.65261905 0.60801372 0.60799514 0.32697116
  0.65776099 0.68785714 0.63328661 0.65212158]
 [0.04909915 0.53166667 0.69238095 0.38448052 0.52457484 0.10091457
  0.52681818 0.5252381  0.54788127 0.51765601]
 [0.248182   0.62318182 0.62404762 0.61873217 0.61895524 0.27108689
  0.60556319 0.64       0.61044614 0.60102182]
 [0.17764476 0.60347222 0.60571429 0.60334022 0.59599817 0.0889472
  0.56083333 0.67380952 0.46211952 0.55118736]
 [0.20833838 0.58823232 0.59047619 0.58214801 0.58604267 0.38771243
  0.67674242 0.67809524 0.65262106 0.67313656]
 [0.43357024 0.70347222 0.71214286 0.68932952 0.70230147 0.54412203
  0.76272727 0.76238095 0.74683644 0.75715651]
 [0.4393093  0.71484848 0.71761905 0.6841907  0.70895457 0.48361786
  0.75454545 0.76047619 0.75878045 0.75336753]
 [0.44820049 0.77       0.80428571 0.71743388 0.76934155 0.46012453
  0.67590909 0.67642857 0.71679827 0.67465196]
 [0.23148912 0.6396978  0.66857143 0.61598904 0.63747529 0.50275126
  0.7667735  0.775      0.73176062 0.7652498 ]
 [0.1570165  0.5650641  0.59547619 0.55070299 0.56154662 0.15935941
  0.56078283 0.56571429 0.54079189 0.55785498]
 [0.57783809 0.79038462 0.80428571 0.79815747 0.79205759 0.3927809
  0.7231685  0.74547619 0.68592963 0.71543346]]
DT mean:
[0.34128761 0.67189846 0.69647619 0.6479892  0.6674994  0.3489667
 0.67213167 0.6897381  0.65421714 0.66739261]
---------------------------
---------------------------
RF performance:
[[ 0.58727311  0.81313131  0.81833333  0.78892026  0.81349091  0.38413066
   0.66958333  0.78142857  0.68138231  0.66571729]
 [ 0.45747836  0.79959596  0.8002381   0.76251723  0.7957199   0.44670537
   0.70373168  0.72785714  0.75538932  0.69888898]
 [ 0.52533494  0.72272727  0.74071429  0.6753837   0.72261721  0.40984476
   0.70742424  0.70833333  0.71016639  0.70396404]
 [ 0.35807025  0.63893939  0.64785714  0.60980342  0.63145269  0.16571876
   0.55404762  0.65404762  0.50983977  0.54995624]
 [ 0.51833296  0.75950855  0.77547619  0.70190125  0.76198292  0.45016252
   0.71590909  0.71571429  0.7596829   0.70951925]
 [ 0.42416973  0.79959596  0.8         0.67648027  0.79853567  0.56758313
   0.78843434  0.79047619  0.80943116  0.7879975 ]
 [ 0.38924639  0.69567308  0.71785714  0.63897598  0.69713457  0.26710524
   0.66727273  0.66857143  0.63191979  0.66169405]
 [ 0.88237734  0.91428571  0.93071429  0.90857366  0.91817943  0.53236081
   0.79407051  0.80619048  0.7825249   0.79517058]
 [ 0.46497396  0.67952381  0.73619048  0.71052664  0.68240653  0.30298389
   0.67833333  0.73642857  0.56380181  0.68004129]
 [ 0.36654445  0.69818182  0.69785714  0.70335804  0.69677717  0.35719029
   0.68782828  0.69285714  0.70927027  0.68419411]
 [ 0.13165408  0.59615385  0.62190476  0.59160483  0.59453957  0.41206822
   0.70827991  0.72714286  0.67968086  0.70697975]
 [ 0.58018939  0.74434524  0.76595238  0.75236231  0.73870697  0.49439212
   0.73221154  0.74738095  0.74305086  0.7296043 ]
 [ 0.35239323  0.6977904   0.70738095  0.61403407  0.69688389  0.18248603
   0.56186869  0.57095238  0.51569095  0.55342719]
 [ 0.14358558  0.60364011  0.6447619   0.57288737  0.60402068  0.40339104
   0.6690404   0.66785714  0.70674132  0.66357678]
 [ 0.33128059  0.62344322  0.65333333  0.56934479  0.61757867  0.35100755
   0.69271978  0.70690476  0.62909534  0.68490144]
 [ 0.28756499  0.69214744  0.70857143  0.67575997  0.69202358  0.39367599
   0.74716117  0.78095238  0.72451729  0.7456774 ]
 [ 0.69780571  0.86137821  0.86857143  0.85325844  0.86171131  0.65875396
   0.80657051  0.81452381  0.73025076  0.80637429]
 [ 0.19795392  0.63480392  0.84404762  0.50327012  0.63556134  0.44803962
   0.74962607  0.7652381   0.70297949  0.75161009]
 [ 0.5066207   0.71214286  0.77595238  0.71065349  0.71409744  0.60078348
   0.77005051  0.77428571  0.7868936   0.76923988]
 [ 0.2844818   0.64093407  0.68214286  0.66916168  0.63930038  0.18986254
   0.6635989   0.70238095  0.60059016  0.66128574]
 [-0.03899168  0.47354167  0.68833333  0.13022191  0.45890735  0.09323434
   0.51681818  0.51714286  0.53238888  0.51448134]
 [ 0.37378829  0.66227273  0.66357143  0.603261    0.65485116  0.32913419
   0.67149725  0.70261905  0.57314035  0.66535938]
 [ 0.1458301   0.55864899  0.57619048  0.53128631  0.55427414  0.23475879
   0.61520833  0.73166667  0.57332743  0.60785123]
 [ 0.3043311   0.60232323  0.60547619  0.60429975  0.59742795  0.3791697
   0.69588384  0.70309524  0.6914555   0.69366398]
 [ 0.51140583  0.75467172  0.76166667  0.7369168   0.75325905  0.55116406
   0.76090909  0.76071429  0.78941687  0.75719402]
 [ 0.40239354  0.70141414  0.70333333  0.59595353  0.69949544  0.47419753
   0.75871212  0.76142857  0.736995    0.75556906]
 [ 0.44288127  0.76142857  0.8247619   0.71485909  0.77587868  0.53752721
   0.76409091  0.765       0.75745053  0.76243794]
 [ 0.21863623  0.59436813  0.64428571  0.54152549  0.59189651  0.41556283
   0.74967949  0.76166667  0.70986133  0.74876627]
 [ 0.21961851  0.63385989  0.67333333  0.56556562  0.62876481  0.17601097
   0.64343434  0.64785714  0.60188614  0.64012129]
 [ 0.6111363   0.82820513  0.83928571  0.82600642  0.82981574  0.50677346
   0.74212454  0.78047619  0.76147523  0.7460307 ]]
RF mean:
[0.3892787  0.69662255 0.73060317 0.65128911 0.69524306 0.39052597
 0.69953736 0.72237302 0.68200988 0.69670985]
---------------------------
---------------------------
SVM performance:
[[0.2396414  0.615      0.63428571 0.53519024 0.58729798 0.
  0.5        0.75119048 0.         0.42892535]
 [0.32395432 0.6590404  0.67404762 0.62123134 0.64762257 0.14469605
  0.56220238 0.66357143 0.30199862 0.5024305 ]
 [0.46521519 0.72083333 0.7552381  0.65362135 0.7088563  0.39066695
  0.69520202 0.69761905 0.69002111 0.69374553]
 [0.22805348 0.60805556 0.63452381 0.52449786 0.58091994 0.
  0.5        0.71714286 0.         0.41757703]
 [0.49565405 0.73215812 0.77642857 0.69664957 0.73929608 0.45333492
  0.72636364 0.72738095 0.71955467 0.72402357]
 [0.35906158 0.67858586 0.68261905 0.64746299 0.66626693 0.47057727
  0.73494949 0.73714286 0.72899148 0.73332721]
 [0.         0.5        0.5952381  0.         0.3730615  0.26294986
  0.63181818 0.6297619  0.61724256 0.62363846]
 [0.76666587 0.87142857 0.90190476 0.86389231 0.8822013  0.40111979
  0.68798077 0.73785714 0.6386893  0.68852487]
 [0.         0.5        0.68809524 0.         0.40754902 0.
  0.5        0.68809524 0.         0.40754902]
 [0.34580454 0.67272727 0.67285714 0.66382312 0.66852616 0.17063967
  0.58078283 0.6102381  0.48002079 0.54571393]
 [0.         0.5        0.6        0.         0.37493316 0.20178663
  0.58958333 0.66357143 0.3717914  0.54129295]
 [0.23363945 0.6032967  0.68738095 0.44349022 0.5717159  0.00538559
  0.50240385 0.6097619  0.03535534 0.3891256 ]
 [0.11295215 0.55069444 0.6197619  0.25128462 0.46564639 0.
  0.5        0.57071429 0.         0.36326979]
 [0.         0.5        0.63928571 0.         0.38991087 0.47771585
  0.73686869 0.74238095 0.72439905 0.73440034]
 [0.         0.5        0.66833333 0.         0.40053476 0.
  0.5        0.64880952 0.         0.39344029]
 [0.         0.5        0.5952381  0.         0.3730615  0.
  0.5        0.66333333 0.         0.39875223]
 [0.30155892 0.63643162 0.69809524 0.51775557 0.60856004 0.
  0.5        0.59047619 0.         0.37118984]
 [0.         0.5        0.84404762 0.         0.45766495 0.
  0.5        0.5952381  0.         0.3730615 ]
 [0.         0.5        0.69761905 0.         0.41088235 0.01042654
  0.505      0.55119048 0.03162278 0.36347141]
 [0.         0.5        0.65357143 0.         0.39520499 0.01780822
  0.50714286 0.63452381 0.03779645 0.39998329]
 [0.         0.5        0.77595238 0.         0.43685114 0.04063482
  0.52090909 0.51190476 0.14393135 0.38647411]
 [0.17675846 0.58863636 0.58547619 0.52724396 0.55756883 0.
  0.5        0.65357143 0.         0.39520499]
 [0.         0.5        0.57071429 0.         0.36326979 0.
  0.5        0.73690476 0.         0.42419562]
 [0.         0.5        0.52690476 0.         0.34499328 0.38973199
  0.68883838 0.71357143 0.63393327 0.67628806]
 [0.07496023 0.53402778 0.59547619 0.16296958 0.42596878 0.43421212
  0.71772727 0.71595238 0.7056903  0.71130587]
 [0.02365438 0.51146465 0.54619048 0.10649527 0.38344479 0.4330014
  0.71300505 0.72809524 0.69270793 0.7103131 ]
 [0.1736553  0.56928571 0.73238095 0.30960289 0.53429676 0.54936516
  0.77409091 0.7752381  0.76350393 0.77082842]
 [0.         0.5        0.63928571 0.         0.38991087 0.13739434
  0.56073718 0.64880952 0.25373963 0.48851961]
 [0.         0.5        0.62452381 0.         0.38435829 0.1205615
  0.55626263 0.5947619  0.34798395 0.48096093]
 [0.633749   0.81153846 0.82880952 0.79525795 0.81202335 0.13998719
  0.55805861 0.69238095 0.30710014 0.51364082]]
SVM mean:
[0.16516594 0.5787735  0.67147619 0.27734896 0.51141329 0.17506653
 0.58499757 0.66670635 0.3075358  0.52170581]
---------------------------
---------------------------
GBM performance:
[[0.50326249 0.74383838 0.75095238 0.73561074 0.74478314 0.25400423
  0.60166667 0.79571429 0.37585164 0.59431996]
 [0.44712628 0.71661616 0.73666667 0.68225428 0.71226757 0.41830853
  0.6834478  0.74595238 0.61018198 0.68308712]
 [0.4812343  0.72878788 0.76071429 0.68417688 0.72214028 0.35615867
  0.68136364 0.68761905 0.65452089 0.67535181]
 [0.22540265 0.61005051 0.62357143 0.58776002 0.60567427 0.05873775
  0.52285714 0.72214286 0.16032924 0.4708171 ]
 [0.4877038  0.73979701 0.78095238 0.69799717 0.74723851 0.45138347
  0.725      0.72642857 0.70424288 0.71830901]
 [0.48851499 0.74025253 0.73809524 0.73599506 0.73301699 0.59737715
  0.79419192 0.80452381 0.77495964 0.79239949]
 [0.35242293 0.66864316 0.71309524 0.6186264  0.66673296 0.39462694
  0.69681818 0.69714286 0.68203651 0.69075799]
 [0.77928776 0.86666667 0.89690476 0.87037309 0.87673662 0.52308639
  0.7525641  0.78619048 0.70636687 0.75283594]
 [0.33115975 0.63666667 0.74214286 0.54444121 0.63236742 0.09451315
  0.53380952 0.69809524 0.21349254 0.4847436 ]
 [0.35477765 0.67272727 0.67261905 0.64718246 0.66504263 0.44211943
  0.71050505 0.72690476 0.68873034 0.70613231]
 [0.12574126 0.55641026 0.61571429 0.45523119 0.53372676 0.4907036
  0.72911325 0.76261905 0.69728562 0.73115861]
 [0.51880396 0.74210165 0.7797619  0.72496344 0.74890571 0.42763346
  0.69871795 0.73714286 0.66728689 0.70141045]
 [0.32486692 0.64400253 0.68238095 0.58721423 0.63692796 0.05356761
  0.52468434 0.56071429 0.44650344 0.50579202]
 [0.05804247 0.52932692 0.64333333 0.25391089 0.47519553 0.42431946
  0.72893939 0.73738095 0.69188938 0.72449396]
 [0.11360154 0.55238095 0.69285714 0.24321465 0.4981042  0.25430202
  0.61675824 0.71261905 0.50297432 0.60130686]
 [0.17463195 0.56869658 0.64404762 0.37143062 0.51264626 0.33004113
  0.64349817 0.74642857 0.54651491 0.64156957]
 [0.7076324  0.8474359  0.85428571 0.83932748 0.8454536  0.41586587
  0.70138889 0.74214286 0.63658043 0.69489501]
 [0.01891496 0.50816993 0.83452381 0.0560112  0.47452269 0.40564526
  0.69786325 0.73166667 0.66099502 0.69798079]
 [0.18525202 0.58       0.72761905 0.35770635 0.55420709 0.47429703
  0.73123737 0.74595238 0.70297957 0.72942455]
 [0.29625022 0.62692308 0.71690476 0.54829364 0.62489343 0.28331155
  0.62875458 0.70690476 0.51764249 0.61620928]
 [0.         0.5        0.77595238 0.         0.43685114 0.10045418
  0.56       0.5602381  0.54836689 0.55442029]
 [0.33295472 0.66227273 0.66261905 0.65460303 0.65577366 0.17712613
  0.58289835 0.68785714 0.43666046 0.56422663]
 [0.29727029 0.6447601  0.68857143 0.54836406 0.61975094 0.14576803
  0.55354167 0.75690476 0.21451374 0.5166794 ]
 [0.15394507 0.57222222 0.57547619 0.54993372 0.56268575 0.36676997
  0.68217172 0.69214286 0.6649419  0.67790154]
 [0.37345669 0.67872475 0.70809524 0.62468213 0.66856412 0.55993113
  0.78454545 0.7852381  0.77219834 0.78026977]
 [0.3379943  0.66530303 0.67833333 0.64342414 0.65814319 0.53576611
  0.76540404 0.77666667 0.75122724 0.76409993]
 [0.3974564  0.67071429 0.78571429 0.59260904 0.68500527 0.51817706
  0.75909091 0.75928571 0.75093752 0.75766903]
 [0.15908881 0.56861264 0.67357143 0.36852408 0.53029979 0.47853713
  0.71864316 0.76595238 0.68007823 0.72106046]
 [0.12782875 0.56215659 0.64428571 0.40472243 0.53596391 0.2946906
  0.63813131 0.65214286 0.62163921 0.63511599]
 [0.58765891 0.79727564 0.815      0.79000317 0.80200611 0.40162553
  0.68214286 0.77095238 0.56720119 0.67660822]]
GBM mean:
[0.32474281 0.65338453 0.72049206 0.54728623 0.63885425 0.35762828
 0.67099163 0.72605556 0.58830431 0.66203489]
---------------------------
---------------------------
BDDAE performance:
[[ 0.05269214  0.52631579  0.53170732  0.51368235  0.52257697  0.01439644
   0.50516129  0.75365854  0.06273133  0.44678373]
 [ 0.20464311  0.60374396  0.60487805  0.5924217   0.59677451  0.52808948
   0.755625    0.78292683  0.74242796  0.76176923]
 [-0.09097535  0.45543478  0.4804878   0.38782664  0.43444856  0.09448257
   0.54678571  0.54878049  0.52911126  0.53911255]
 [-0.10005872  0.45035885  0.46097561  0.41040992  0.43585153  0.13993185
   0.5591954   0.72195122  0.31902416  0.53124883]
 [ 0.40767733  0.698375    0.72682927  0.67943309  0.69979883  0.35090913
   0.67571429  0.67560976  0.67027749  0.67303084]
 [ 0.55096902  0.77547619  0.77560976  0.76454936  0.77151506 -0.06739612
   0.46662679  0.47804878  0.42549508  0.45217715]
 [ 0.00932297  0.50539216  0.54146341  0.41517858  0.47821481  0.2049935
   0.60261905  0.60243902  0.59849051  0.60042654]
 [ 0.37034545  0.66401099  0.76341463  0.59197169  0.6712389  -0.08763823
   0.46125     0.54878049  0.19044124  0.39667532]
 [ 0.52799484  0.73777473  0.82195122  0.6838607   0.75324168  0.41556225
   0.67307692  0.79268293  0.5815713   0.68684339]
 [-0.08581955  0.45702381  0.45853659  0.44330806  0.45099533  0.18879403
   0.59347826  0.60487805  0.57127926  0.58655079]
 [-0.01338781  0.493625    0.55121951  0.38108977  0.47244082  0.21036507
   0.59571078  0.65121951  0.49521691  0.57256989]
 [-0.08731371  0.457375    0.5097561   0.38136393  0.44265129  0.37936336
   0.692375    0.69756098  0.68643281  0.6863429 ]
 [-0.00172474  0.49901961  0.52195122  0.47543325  0.49588154  0.31630092
   0.65917874  0.66097561  0.65425689  0.6557369 ]
 [ 0.14629222  0.56653846  0.64878049  0.44124306  0.54724987  0.28879905
   0.64366029  0.64878049  0.63644053  0.64229061]
 [-0.01136892  0.49484127  0.59512195  0.36798484  0.47435761  0.09243543
   0.54351852  0.63658537  0.38050212  0.51420395]
 [ 0.12514712  0.56102941  0.59756098  0.48141233  0.53802386  0.15670266
   0.56243386  0.7         0.34996576  0.51822372]
 [ 0.56018716  0.79276961  0.7804878   0.77009073  0.77084864  0.2676899
   0.6252451   0.67073171  0.55060271  0.60943291]
 [ 0.30129263  0.63261905  0.85609756  0.5021276   0.64358308 -0.00222139
   0.49852941  0.55853659  0.34375293  0.45198453]
 [ 0.15431546  0.57068966  0.68292683  0.49275523  0.56957524  0.33743006
   0.66746411  0.67317073  0.65144093  0.66257308]
 [ 0.2120051   0.59140212  0.69512195  0.47795624  0.57933186  0.01794937
   0.50807692  0.61219512  0.25970847  0.45765363]
 [ 0.00411069  0.50173611  0.77073171  0.04639804  0.45148379  0.17315173
   0.58678571  0.58536585  0.576209    0.58088184]
 [ 0.04046048  0.5202381   0.5195122   0.5125806   0.51599869  0.00753915
   0.50238095  0.63902439  0.2259488   0.44332243]
 [-0.01221164  0.4942029   0.5097561   0.47067575  0.4894735   0.45821654
   0.70348485  0.81463415  0.65337699  0.72303971]
 [ 0.32789692  0.66351675  0.66585366  0.65651456  0.660986    0.25414922
   0.62427536  0.64146341  0.59922743  0.61951778]
 [ 0.15189604  0.57439614  0.5902439   0.5547041   0.57101831  0.14992913
   0.5747619   0.57560976  0.571429    0.57357048]
 [ 0.23705794  0.61674641  0.62682927  0.58757773  0.6075985   0.14492767
   0.57149758  0.58292683  0.55716192  0.5684357 ]
 [ 0.41561091  0.69752747  0.75853659  0.67469065  0.70611576  0.46027498
   0.72904762  0.73170732  0.71768966  0.72587773]
 [ 0.07232869  0.53307692  0.5902439   0.48127242  0.52808075  0.46073205
   0.724       0.75121951  0.70871174  0.72745314]
 [ 0.10533418  0.54871795  0.59756098  0.49960009  0.54084201  0.35898353
   0.67643541  0.68780488  0.64999173  0.66982985]
 [ 0.31589958  0.650375    0.6902439   0.61970774  0.65161664 -0.02963096
   0.48809524  0.62926829  0.11986605  0.41581821]]
BDDAE mean:
[0.16302065 0.57781164 0.63081301 0.51192736 0.56906046 0.20950708
 0.60054967 0.65528455 0.50262607 0.58311258]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.53690476 0.         0.34929435 0.
  0.5        0.75119048 0.         0.42892535]
 [0.         0.5        0.55119048 0.         0.35526026 0.
  0.5        0.61952381 0.         0.38246435]
 [0.         0.5        0.56571429 0.         0.36125367 0.
  0.5        0.52190476 0.         0.34284274]
 [0.         0.5        0.54642857 0.         0.35327163 0.
  0.5        0.71714286 0.         0.41757703]
 [0.         0.5        0.6047619  0.         0.37680481 0.
  0.5        0.50714286 0.         0.33642473]
 [0.         0.5        0.51690476 0.         0.3406922  0.
  0.5        0.53690476 0.         0.34929435]
 [0.         0.5        0.5952381  0.         0.3730615  0.
  0.5        0.50238095 0.         0.3343078 ]
 [0.         0.5        0.68333333 0.         0.40588235 0.
  0.5        0.60952381 0.         0.37867647]
 [0.         0.5        0.68809524 0.         0.40754902 0.
  0.5        0.68809524 0.         0.40754902]
 [0.         0.5        0.51190476 0.         0.33854167 0.
  0.5        0.55119048 0.         0.35526026]
 [0.         0.5        0.6        0.         0.37493316 0.
  0.5        0.5952381  0.         0.3730615 ]
 [0.         0.5        0.61452381 0.         0.38057041 0.
  0.5        0.60952381 0.         0.37867647]
 [0.         0.5        0.58071429 0.         0.36730205 0.
  0.5        0.57071429 0.         0.36326979]
 [0.         0.5        0.63928571 0.         0.38991087 0.
  0.5        0.53690476 0.         0.34929435]
 [0.         0.5        0.66833333 0.         0.40053476 0.
  0.5        0.64880952 0.         0.39344029]
 [0.         0.5        0.5952381  0.         0.3730615  0.
  0.5        0.66333333 0.         0.39875223]
 [0.         0.5        0.59047619 0.         0.37118984 0.
  0.5        0.59047619 0.         0.37118984]
 [0.         0.5        0.84404762 0.         0.45766495 0.
  0.5        0.5952381  0.         0.3730615 ]
 [0.         0.5        0.69761905 0.         0.41088235 0.
  0.5        0.54642857 0.         0.35327163]
 [0.         0.5        0.65357143 0.         0.39520499 0.
  0.5        0.62952381 0.         0.38625223]
 [0.         0.5        0.77595238 0.         0.43685114 0.
  0.5        0.48809524 0.         0.32795699]
 [0.         0.5        0.50714286 0.         0.33642473 0.
  0.5        0.65357143 0.         0.39520499]
 [0.         0.5        0.57071429 0.         0.36326979 0.
  0.5        0.73690476 0.         0.42419562]
 [0.         0.5        0.52690476 0.         0.34499328 0.
  0.5        0.55119048 0.         0.35526026]
 [0.         0.5        0.56571429 0.         0.36125367 0.
  0.5        0.51190476 0.         0.33854167]
 [0.         0.5        0.53690476 0.         0.34929435 0.
  0.5        0.56071429 0.         0.35923754]
 [0.         0.5        0.69285714 0.         0.40921569 0.
  0.5        0.50238095 0.         0.3343078 ]
 [0.         0.5        0.63928571 0.         0.38991087 0.
  0.5        0.6047619  0.         0.37680481]
 [0.         0.5        0.62452381 0.         0.38435829 0.
  0.5        0.54642857 0.         0.35327163]
 [0.         0.5        0.60952381 0.         0.37867647 0.
  0.5        0.66333333 0.         0.39875223]]
DUMMY mean:
[0.         0.5        0.61112698 0.         0.37790382 0.
 0.5        0.59368254 0.         0.37123752]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_6
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  8.0
step (sec):  6.0
overlap:  True
perc. of overlap:  25.0
Number of windows / instances:  205
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.375 0.684 0.722 0.648 0.682 0.392 0.693 0.719 0.672 0.692]
 [0.341 0.672 0.696 0.648 0.667 0.349 0.672 0.69  0.654 0.667]
 [0.389 0.697 0.731 0.651 0.695 0.391 0.7   0.722 0.682 0.697]
 [0.165 0.579 0.671 0.277 0.511 0.175 0.585 0.667 0.308 0.522]
 [0.325 0.653 0.72  0.547 0.639 0.358 0.671 0.726 0.588 0.662]
 [0.163 0.578 0.631 0.512 0.569 0.21  0.601 0.655 0.503 0.583]
 [0.    0.5   0.611 0.    0.378 0.    0.5   0.594 0.    0.371]]
Elapsed time: 511.23503913084664 minutes
Elapsed time: 8.520583985514111 hours
